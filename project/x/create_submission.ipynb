{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec688b5f",
   "metadata": {
    "id": "997c9bf8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982adbb4",
   "metadata": {
    "id": "ee74646f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch # 1.9\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "import pickle\n",
    "\n",
    "# 導入dicom套件\n",
    "from pydicom import dcmread\n",
    "from pydicom.data import get_testdata_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26a50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import getAllDataPath, CustomImageDataset, show_image\n",
    "from utils.unet import UNet, ResUnet, AttUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63360421",
   "metadata": {
    "id": "937beac5"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8 # 8 for 256x256/ 16 for 128x128\n",
    "NUM_LABELS = 1\n",
    "WIDTH = 256\n",
    "HEIGHT = 256 \n",
    "MULTI_CHANNELS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320c99e",
   "metadata": {
    "id": "05f523cb"
   },
   "source": [
    "### 取得image list\n",
    "輸出: data_dic (字典)\n",
    "- key: X_test, X_test, y_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c25467",
   "metadata": {
    "id": "c37c6103"
   },
   "outputs": [],
   "source": [
    "root = 'data/CHAOS_AIAdatasets/1_Domain_Gernalization_dataset/Test_Sets'\n",
    "dic = {}\n",
    "for a,b,c in os.walk(root, topdown=True):\n",
    "    if len(c)>0: # 當前目錄內包含檔案\n",
    "        if not a.__contains__('OutPhase'):\n",
    "            dic[a] = c\n",
    "dataset = {}\n",
    "lis = ['CT', 'MRI']\n",
    "for task in lis:\n",
    "    class_lis = []\n",
    "    for sub_folder in dic.keys():\n",
    "        if task in sub_folder.split('/'):\n",
    "            class_lis+=[sub_folder+'/'+filename for filename in dic[sub_folder]]\n",
    "    dataset[task] = class_lis\n",
    "\n",
    "dataset['CT_test'] = sorted([i for i in dataset['CT'] if 'dcm' in i])\n",
    "\n",
    "dataset['MRI_DICOM_anon'] = sorted([i for i in dataset['MRI'] if 'dcm' in i])\n",
    "\n",
    "dataset['MRI_T2SPIR_test'] = sorted([i for i in dataset['MRI_DICOM_anon'] if 'T2SPIR' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a804d4",
   "metadata": {
    "id": "4dc6952f"
   },
   "outputs": [],
   "source": [
    "MRI_test = list(dataset['MRI_T2SPIR_test'])\n",
    "CT_test = list(dataset['CT_test'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930156d",
   "metadata": {
    "id": "42354a98"
   },
   "source": [
    "#### 使用albumentations進行資料擴增"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73aa93f7",
   "metadata": {
    "id": "2d6c1f7d"
   },
   "outputs": [],
   "source": [
    "# https://albumentations.ai/docs/getting_started/mask_augmentation/\n",
    "target_transform = A.Compose([\n",
    "    A.Resize(WIDTH, HEIGHT),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5bb15",
   "metadata": {
    "id": "8fdd31b3"
   },
   "source": [
    "### 建立DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2886ca9a",
   "metadata": {
    "id": "10c73b9b"
   },
   "outputs": [],
   "source": [
    "# 建議同時間只有8個(256,256)的sample進行計算 (Total = BATCH_SIZE*MULTIPLE_BATCH)\n",
    "\n",
    "dataset_test = CustomImageDataset(MRI_test, transform=target_transform)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "CT_dataset_test = CustomImageDataset(CT_test, transform=target_transform)\n",
    "CT_dataloader_test = torch.utils.data.DataLoader(CT_dataset_test, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f1448",
   "metadata": {
    "id": "a6fa51d8"
   },
   "source": [
    "## 測試模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5111d8b3",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "a9de6ec42279424b86ed6b9981ffd8e1"
     ]
    },
    "id": "1046d885",
    "outputId": "076a22eb-6d80-4983-b4c7-89989ef7dce7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66ab76eae2d4462813e7cfcaebb9964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Testing DataSet', options=('CT_dataloader_test', 'dataloader_test'), value='CT_data…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dic = dict(zip(\n",
    "    ['dataloader_test', 'CT_dataloader_test'],\n",
    "    [dataloader_test, CT_dataloader_test]\n",
    "))\n",
    "\n",
    "w = widgets.ToggleButtons(\n",
    "    options=['CT_dataloader_test', 'dataloader_test', ],\n",
    "    description='Testing DataSet',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "#     tooltips=['Description of slow', 'Description of regular', 'Description of fast'],\n",
    "#     icons=['check'] * 3\n",
    ")\n",
    "\n",
    "display(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "293e1adb",
   "metadata": {
    "id": "f6ea018c"
   },
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    \"\"\"\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    \"\"\"\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d470199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "title: create model\n",
    "---\n",
    "補充:\n",
    "- 要在建立optimizer之前就把model的參數移到gpu裡面(也就是在把參數託管給optim以前)\n",
    "ref: \n",
    "- https://pytorch.org/docs/stable/optim.html \n",
    "- Road Extraction by Deep Residual U-Net, 2017\n",
    "- U-Net: Convolutional Networks for Biomedical Image Segmentation, 2015\n",
    "- Attention U-Net: Learning Where to Look for the Pancreas, 2018\n",
    "'''\n",
    "\n",
    "device = 'cuda:0'\n",
    "save_root = './data/save_weights/'\n",
    "\n",
    "model = UNet\n",
    "# model = ResUnet # suggest: only use it for single channel outputs, Sigmoid activation, Dice loss or focal loss\n",
    "# model = AttUnet # better ResUnet \n",
    "model = model((WIDTH, HEIGHT), in_ch=1, out_ch=1, activation=None).to(device)\n",
    "filepath = f'{save_root}model.bin'\n",
    "model.load_state_dict(torch.load(filepath)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7518fe67",
   "metadata": {
    "id": "d5ae006f",
    "outputId": "e25be714-1588-4157-9de4-d67baf1db052"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173\n",
      "1173\n",
      "complete\n",
      "160\n",
      "160\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "ST_submission = []\n",
    "for file_list, dataloader in zip([CT_test, MRI_test], [CT_dataloader_test, dataloader_test]):\n",
    "    test_list = [['-'.join([str(i.split('/')[idx]) for idx in [-4,-3,-1]])] for i in file_list]\n",
    "#     len(CT_test_list)\n",
    "\n",
    "    dataloader = iter(dataloader)\n",
    "    print(len(file_list))\n",
    "    i = 0\n",
    "    while 1:\n",
    "        try:\n",
    "            image= dataloader.next()\n",
    "            image = image.to(device)\n",
    "\n",
    "            outputs = model(image)\n",
    "            \n",
    "            # 調整一個合適的閾值\n",
    "            thres = 0\n",
    "            outputs[outputs<thres] = 0 \n",
    "            outputs[outputs!=0] = 1\n",
    "            outputs = outputs.long()\n",
    "            outputs = outputs.detach().cpu()\n",
    "\n",
    "            for out in outputs:\n",
    "                test_list[i].append(mask2rle(out))\n",
    "\n",
    "                i += 1\n",
    "            print(i, end='\\r')\n",
    "        except StopIteration:\n",
    "            print(i)\n",
    "            print('complete')\n",
    "            break\n",
    "    ST_submission+=test_list\n",
    "    assert i==len(test_list)\n",
    "    \n",
    "pd.DataFrame(ST_submission, columns=['filename', 'rle']).to_csv(f'{save_root}ST_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22511467",
   "metadata": {
    "id": "a8942c65"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    if get_ipython().__class__.__name__=='ZMQInteractiveShell':\n",
    "        os.system('jupyter nbconvert create_submission.ipynb --to python')\n",
    "except NameError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CHAOS_CT_MRI_create_submission.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
