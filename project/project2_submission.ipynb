{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3b1041",
   "metadata": {
    "id": "997c9bf8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a690019e",
   "metadata": {
    "id": "ee74646f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch # 1.9\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "import pickle\n",
    "\n",
    "# 導入dicom套件\n",
    "from pydicom import dcmread\n",
    "from pydicom.data import get_testdata_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2475f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import getAllDataPath, CustomImageDataset, show_image\n",
    "from utils.unet import UNet, ResUnet, AttUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704425dd",
   "metadata": {
    "id": "937beac5"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8 # 8 for 256x256/ 16 for 128x128\n",
    "NUM_LABELS = 1\n",
    "WIDTH = 256\n",
    "HEIGHT = 256 \n",
    "MULTI_CHANNELS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df1d14",
   "metadata": {
    "id": "05f523cb"
   },
   "source": [
    "### 取得image list\n",
    "輸出: data_dic (字典)\n",
    "- key: X_test, X_test, y_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0594d0b9",
   "metadata": {
    "id": "c37c6103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data/CHAOS_AIAdatasets/2_Domain_Adaptation_dataset/testset/34/T2SPIR/DICOM_anon', 'data/CHAOS_AIAdatasets/2_Domain_Adaptation_dataset/testset/36/T2SPIR/DICOM_anon', 'data/CHAOS_AIAdatasets/2_Domain_Adaptation_dataset/testset/39/T2SPIR/DICOM_anon', 'data/CHAOS_AIAdatasets/2_Domain_Adaptation_dataset/testset/38/T2SPIR/DICOM_anon', 'data/CHAOS_AIAdatasets/2_Domain_Adaptation_dataset/testset/37/T2SPIR/DICOM_anon'])\n"
     ]
    }
   ],
   "source": [
    "root = 'data/CHAOS_AIAdatasets/2_Domain_Adaptation_dataset/testset'\n",
    "dic = {}\n",
    "for a,b,c in os.walk(root, topdown=True):\n",
    "    if len(c)>0: # 當前目錄內包含檔案\n",
    "        if not a.__contains__('OutPhase'):\n",
    "            dic[a] = c\n",
    "print(dic.keys())\n",
    "dataset = {}\n",
    "lis = ['testset']\n",
    "for task in lis:\n",
    "    class_lis = []\n",
    "    for sub_folder in dic.keys():\n",
    "        if task in sub_folder.split('/'):\n",
    "            class_lis+=[sub_folder+'/'+filename for filename in dic[sub_folder]]\n",
    "    dataset[task] = class_lis\n",
    "\n",
    "# dataset['CT_test'] = sorted([i for i in dataset['CT'] if 'dcm' in i])\n",
    "\n",
    "dataset['MRI_DICOM_anon'] = sorted([i for i in dataset['testset'] if 'dcm' in i])\n",
    "\n",
    "dataset['MRI_T2SPIR_test'] = sorted([i for i in dataset['MRI_DICOM_anon'] if 'T2SPIR' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b647d6a3",
   "metadata": {
    "id": "4dc6952f"
   },
   "outputs": [],
   "source": [
    "MRI_test = list(dataset['MRI_T2SPIR_test'])\n",
    "\n",
    "# MRI_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84905563",
   "metadata": {
    "id": "42354a98"
   },
   "source": [
    "#### 使用albumentations進行資料擴增"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffed20a",
   "metadata": {
    "id": "2d6c1f7d"
   },
   "outputs": [],
   "source": [
    "# https://albumentations.ai/docs/getting_started/mask_augmentation/\n",
    "target_transform = A.Compose([\n",
    "    A.Resize(WIDTH, HEIGHT),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80721824",
   "metadata": {
    "id": "8fdd31b3"
   },
   "source": [
    "### 建立DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af3a89c",
   "metadata": {
    "id": "10c73b9b"
   },
   "outputs": [],
   "source": [
    "# 建議同時間只有8個(256,256)的sample進行計算 (Total = BATCH_SIZE*MULTIPLE_BATCH)\n",
    "\n",
    "dataset_test = CustomImageDataset(MRI_test, transform=target_transform)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03356269",
   "metadata": {
    "id": "a6fa51d8"
   },
   "source": [
    "## 測試模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a83b62a2",
   "metadata": {
    "id": "f6ea018c"
   },
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    \"\"\"\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    \"\"\"\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba81868",
   "metadata": {},
   "source": [
    "## title: create model\n",
    "\n",
    "### example\n",
    "```\n",
    "save_root = './data/save_weights/'\n",
    "\n",
    "'from normal pytorch'\n",
    "# model = UNet\n",
    "# device = 'cuda:0'\n",
    "# model = model((WIDTH, HEIGHT), in_ch=1, out_ch=1, activation=None).to(device)\n",
    "# save_root = './data/save_weights/'\n",
    "# filepath = f'{save_root}model.bin'\n",
    "# model.load_state_dict(torch.load(filepath)) \n",
    "\n",
    "# 'pytorch-lightning'\n",
    "# checkpoint = torch.load('data/save_weights/epoch=99_train_loss=775.5070_model.ckpt')\n",
    "# model = unetModel(model)\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "756f48c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_root = './data/save_weights/'\n",
    "# device = 'cuda:0'\n",
    "\n",
    "# model = UNet\n",
    "# model = model((WIDTH, HEIGHT), in_ch=1, out_ch=1, activation=None).to(device)\n",
    "# save_root = './data/save_weights/'\n",
    "# filepath = f'{save_root}model.bin'\n",
    "# model.load_state_dict(torch.load(filepath)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "769226f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DomainClassifier\n",
    "discrimator = DomainClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53749176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.head.weight\n",
      "encoder.head.bias\n",
      "encoder.input.conv1.weight\n",
      "encoder.input.conv2.weight\n",
      "encoder.input.INorm.weight\n",
      "encoder.input.INorm.bias\n",
      "encoder.down_list.0.conv.conv1.weight\n",
      "encoder.down_list.0.conv.conv2.weight\n",
      "encoder.down_list.0.conv.INorm.weight\n",
      "encoder.down_list.0.conv.INorm.bias\n",
      "encoder.down_list.1.conv.conv1.weight\n",
      "encoder.down_list.1.conv.conv2.weight\n",
      "encoder.down_list.1.conv.INorm.weight\n",
      "encoder.down_list.1.conv.INorm.bias\n",
      "encoder.down_list.2.conv.conv1.weight\n",
      "encoder.down_list.2.conv.conv2.weight\n",
      "encoder.down_list.2.conv.INorm.weight\n",
      "encoder.down_list.2.conv.INorm.bias\n",
      "encoder.down_list.3.conv.conv1.weight\n",
      "encoder.down_list.3.conv.conv2.weight\n",
      "encoder.down_list.3.conv.INorm.weight\n",
      "encoder.down_list.3.conv.INorm.bias\n",
      "encoder.up_list.0.up.1.weight\n",
      "encoder.up_list.0.up.1.bias\n",
      "encoder.up_list.0.conv.conv1.weight\n",
      "encoder.up_list.0.conv.conv2.weight\n",
      "encoder.up_list.0.conv.INorm.weight\n",
      "encoder.up_list.0.conv.INorm.bias\n",
      "encoder.up_list.1.up.1.weight\n",
      "encoder.up_list.1.up.1.bias\n",
      "encoder.up_list.1.conv.conv1.weight\n",
      "encoder.up_list.1.conv.conv2.weight\n",
      "encoder.up_list.1.conv.INorm.weight\n",
      "encoder.up_list.1.conv.INorm.bias\n",
      "encoder.up_list.2.up.1.weight\n",
      "encoder.up_list.2.up.1.bias\n",
      "encoder.up_list.2.conv.conv1.weight\n",
      "encoder.up_list.2.conv.conv2.weight\n",
      "encoder.up_list.2.conv.INorm.weight\n",
      "encoder.up_list.2.conv.INorm.bias\n",
      "encoder.up_list.3.up.1.weight\n",
      "encoder.up_list.3.up.1.bias\n",
      "encoder.up_list.3.conv.conv1.weight\n",
      "encoder.up_list.3.conv.conv2.weight\n",
      "encoder.up_list.3.conv.INorm.weight\n",
      "encoder.up_list.3.conv.INorm.bias\n",
      "discrimator.blocks.0.cell.0.weight\n",
      "discrimator.blocks.0.cell.0.bias\n",
      "discrimator.blocks.0.cell.1.weight\n",
      "discrimator.blocks.0.cell.1.bias\n",
      "discrimator.blocks.0.cell.1.running_mean\n",
      "discrimator.blocks.0.cell.1.running_var\n",
      "discrimator.blocks.0.cell.1.num_batches_tracked\n",
      "discrimator.output.1.weight\n",
      "discrimator.output.1.bias\n",
      "discrimator.output.3.weight\n",
      "discrimator.output.3.bias\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from lightning_utils import unetModel, discModel, unetWithDiscModel\n",
    "save_root = './data/save_weights/'\n",
    "device = 'cuda:0'\n",
    "\n",
    "'pytorch-lightning'\n",
    "checkpoint = torch.load('data/save_weights/0513-0041_epoch=194_train_loss=24.9413_model.ckpt')\n",
    "model = UNet\n",
    "model = model((WIDTH, HEIGHT), in_ch=1, out_ch=1, activation=None).to(device)\n",
    "# model = unetModel(model)\n",
    "# model = discModel(model, discrimator, early_stop=0.5)\n",
    "# model = unetWithDiscModel(model, discrimator)\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "for k in checkpoint['state_dict']:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ec1f1",
   "metadata": {
    "id": "d5ae006f",
    "outputId": "e25be714-1588-4157-9de4-d67baf1db052"
   },
   "outputs": [],
   "source": [
    "ST_submission = []\n",
    "for file_list, dataloader in zip([MRI_test], [dataloader_test]):\n",
    "    test_list = [['-'.join([str(i.split('/')[idx]) for idx in [-4,-3,-1]])] for i in file_list]\n",
    "#     len(CT_test_list)\n",
    "\n",
    "    dataloader = iter(dataloader)\n",
    "    print(len(file_list))\n",
    "    i = 0\n",
    "    while 1:\n",
    "        try:\n",
    "            image= dataloader.next()\n",
    "            image = image.to(device)\n",
    "\n",
    "            outputs = model(image)\n",
    "            \n",
    "            # 調整一個合適的閾值\n",
    "            thres = 0\n",
    "            outputs[outputs<thres] = 0 \n",
    "            outputs[outputs!=0] = 1\n",
    "            outputs = outputs.long()\n",
    "            outputs = outputs.detach().cpu()\n",
    "\n",
    "            for out in outputs:\n",
    "                test_list[i].append(mask2rle(out))\n",
    "\n",
    "                i += 1\n",
    "            print(i, end='\\r')\n",
    "        except StopIteration:\n",
    "            print(i)\n",
    "            print('complete')\n",
    "            break\n",
    "    ST_submission+=test_list\n",
    "    assert i==len(test_list)\n",
    "    \n",
    "pd.DataFrame(ST_submission, columns=['filename', 'rle']).to_csv(f'{save_root}ST_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ff9b7",
   "metadata": {
    "id": "a8942c65"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    if get_ipython().__class__.__name__=='ZMQInteractiveShell':\n",
    "        os.system('jupyter nbconvert project2_submission.ipynb --to python')\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d63c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CHAOS_CT_MRI_create_submission.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
