{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a724e4cc",
   "metadata": {
    "id": "iGi60Uey47Mi"
   },
   "source": [
    "## 測試模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25c8b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT_data train (2299, 2)\n",
      "CT_data test (575, 2)\n",
      "MRI_data train (123, 2)\n",
      "MRI_data test (31, 2)\n",
      "MRI_imgOnly_data train (309,)\n"
     ]
    }
   ],
   "source": [
    "from unet import UNet\n",
    "from dataset import getAllDataPath, CTMRI_ImageDataset\n",
    "from criterion import DiceLoss, FocalLoss\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10021af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved/0420-1/model_MRI.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_root = 'saved/0420-1/'\n",
    "dice_criterion = DiceLoss()\n",
    "WIDTH = 256\n",
    "HEIGHT = 256 \n",
    "BATCH_SIZE = 8\n",
    "device = 'cuda:0'\n",
    "\n",
    "filepath = f'{save_root}model_MRI.bin'\n",
    "print(filepath)\n",
    "# model_MRI =  Unet(out_sz=(HEIGHT, WIDTH), out_channels=out_channels, activation=nn.Sigmoid(), multi_level=0).to(device)\n",
    "# model_MRI =  UNet(out_sz=(HEIGHT, WIDTH), num_class=1, activation=None).to(device)\n",
    "model_MRI =  UNet(out_sz=(HEIGHT, WIDTH), num_class=1, enc_chs=(1,64,128,256,512,1024),\n",
    "                  activation=None, # nn.Softmax(dim=1)\n",
    "                 ).to(device) \n",
    "\n",
    "model_MRI.load_state_dict(torch.load(filepath)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fafc87e",
   "metadata": {
    "id": "sFhkIqgyaeyh"
   },
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "effa9419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI_testset train (160, 2)\n"
     ]
    }
   ],
   "source": [
    "root = '/home/jovyan/DA/DATA/TA_data/CHAOS_AIAdatasets/2_Domain_Adaptation_dataset/MRI_testset/'\n",
    "MRI_testset = getAllDataPath(root, test_split_size=None)\n",
    "\n",
    "\n",
    "for data in ['MRI_testset']:\n",
    "    i = eval(data)\n",
    "    for k in i.keys():\n",
    "        print(data,k, np.shape(i[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2eb85f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = A.Compose([\n",
    "#     A.Normalize(p=1, mean=(0.485), std=(0.229)),                         \n",
    "    A.ToFloat(always_apply=True),\n",
    "    A.Resize(WIDTH, HEIGHT),\n",
    "])\n",
    "\n",
    "dataset_test = CTMRI_ImageDataset(MRI_testset['train'], transform=target_transform) # **如果要正式使用要記得把這裡換成X_test\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a26a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE: 8\n",
      "---\n",
      "dataloader_test 20\n",
      "[torch.Size([8, 1, 256, 256]), torch.Size([8, 1, 256, 256])]\n"
     ]
    }
   ],
   "source": [
    "print('BATCH_SIZE:', BATCH_SIZE)\n",
    "for i in ['dataloader_test']:\n",
    "    loader = eval(i)\n",
    "    print('---')\n",
    "    print(i, loader.__len__())\n",
    "    print([i.shape for i in iter(loader).next()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c1fcb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3254, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader = dataloader_test\n",
    "\n",
    "testing_loss = 0.0\n",
    "# 建立3個block\n",
    "\n",
    "with torch.no_grad(): # 避免torch計算gradient產生記憶體負擔\n",
    "    for i, data in enumerate(test_dataloader, 1): \n",
    "        torch.cuda.empty_cache()\n",
    "        image, mask = data\n",
    "\n",
    "        image = image.to(device)\n",
    "        mask = mask.to(device)\n",
    "        outputs = model_MRI(image)\n",
    "#         outputs = F.sigmoid(outputs)\n",
    "    \n",
    "#         samp = outputs[outputs>0.01].detach().cpu().numpy()\n",
    "#         samp = np.unique(np.around(samp, 2), return_counts=True)\n",
    "#         print(outputs[outputs>0.05].unique())\n",
    "#         outputs = F.softmax(outputs, dim=1)\n",
    "#         for out, ma in zip(outputs, mask):\n",
    "#             out = out[1]\n",
    "# #             print(out.shape, ma.shape)\n",
    "#             out = out.unsqueeze(0)\n",
    "# #             print(out[ma==1])\n",
    "#         outputs = outputs[:,1,:,:]\n",
    "#         outputs = outputs.unsqueeze(1)\n",
    "\n",
    "        'asd'\n",
    "        threshold = 0\n",
    "        outputs[outputs>threshold] = 1.\n",
    "        outputs[outputs!=1.] = 0.\n",
    "        outputs = outputs\n",
    "#         outputs = torch.ones(outputs.data.size()).to(device)\n",
    "        \n",
    "#         for o in outputs:\n",
    "#             print(o.sum())\n",
    "#         outputs = outputs.argmax(dim=1)\n",
    "\n",
    "        loss = DiceLoss()(outputs, mask)\n",
    "        testing_loss += loss\n",
    "        \n",
    "loss =  testing_loss/len(test_dataloader)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f5b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全猜0: diceloss: tensor(0.6115, device='cuda:0')\n",
    "# 全猜1: diceloss: tensor(0.9462, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bd24ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    \"\"\"\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    \"\"\"\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f05edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "160\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "submission = []\n",
    "for file_list, dataloader in zip([MRI_testset['train']], [dataloader_test]):\n",
    "#     print(file_list)\n",
    "    test_list = [['-'.join([str(i[0].split('/')[idx]) for idx in [-4,-3,-1]])] for i in file_list]\n",
    "#     len(CT_test_list)\n",
    "\n",
    "    dataloader = iter(dataloader)\n",
    "    print(len(file_list))\n",
    "    i = 0\n",
    "    while 1:\n",
    "        try:\n",
    "            image, mask = dataloader.next()\n",
    "            image = image.to(device)\n",
    "#             mask = mask.to(device)\n",
    "            \n",
    "            outputs= model_MRI(image)\n",
    "        \n",
    "            if outputs.data.size()[1] > 1:\n",
    "                outputs = outputs.transpose(1,-1)\n",
    "                pred = clf.predict(outputs.reshape(-1,2).detach().cpu().numpy())\n",
    "                pred = torch.Tensor(pred).to(device)\n",
    "                outputs = pred.reshape(mask.data.size())#.detach().cpu().numpy()\n",
    "            else:\n",
    "                outputs[outputs>threshold] = 1.\n",
    "                outputs[outputs!=1] = 0.\n",
    "                outputs = outputs.detach().cpu().numpy()\n",
    "#                 outputs = outputs.detach().cpu().numpy()\n",
    "            \n",
    "            #outputs = outputs#.detach().cpu().numpy()\n",
    "#             outputs = torch.zeros(image.data.size())\n",
    "            for out in outputs:\n",
    "                test_list[i].append(mask2rle(out))\n",
    "\n",
    "                i += 1\n",
    "        except StopIteration:\n",
    "            print(i)\n",
    "            print('complete')\n",
    "            break\n",
    "    submission+=test_list\n",
    "    assert i==len(test_list)\n",
    "    \n",
    "pd.DataFrame(submission, columns=['filename', 'rle']).to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "168b30a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook testing_submission.ipynb to python\n",
      "[NbConvertApp] Writing 5308 bytes to testing_submission.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    if get_ipython().__class__.__name__=='ZMQInteractiveShell':\n",
    "        os.system('jupyter nbconvert testing_submission.ipynb --to python')\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196e0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
